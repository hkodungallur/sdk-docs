<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE concept
  PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept xml:lang="en-us" id="concepteEnvConfig">
	<title>Configuring the environment</title>
	<shortdesc>The <codeph>CouchbaseEnvironment</codeph> class enables you to configure Java SDK
		options for bootstrapping, timeouts, reliability, and performance.</shortdesc>

	<conbody>
		<section>
			<title>The environment builder</title>

			<p>Because <codeph>CouchbaseEnvironment</codeph> is an immutable class, you need to configure it
				by using its embedded <codeph>Builder</codeph> class. It is designed to apply the
				builder arguments in a fluent fashion and then create the
					<codeph>CouchbaseEnvironment</codeph> at the very end:</p>

<codeblock outputclass="language-java"><![CDATA[CouchbaseEnvironment env = DefaultCouchbaseEnvironment
    .builder()
    .sslEnabled(true)
    .computationPoolSize(5)
    .build();

Cluster cluster = CouchbaseCluster.create(env, "localhost");]]></codeblock>

			<p>Alternatively, most options are tunable through system properties as well. If a system property is set, it always takes precedence over the builder setting:</p>

<codeblock outputclass="language-java"><![CDATA[System.setProperty("com.couchbase.kvEndpoints", "3");
CouchbaseEnvironment environment = DefaultCouchbaseEnvironment
	.builder()
    .kvEndpoints(2)
    .build();
CouchbaseCluster cluster = CouchbaseCluster.create(environment);]]></codeblock>

			<p>All system properties start with the <codeph>com.couchbase</codeph> prefix.</p>

		</section>

		<section>
			<title>Configuration Options</title>

			<p>The following tables cover all possible configuration options and explain their usage and
				default values. The tables categorize the options into groups for bootstrapping,
				timeout, reliability, performance, and advanced options.</p>
		
			<table>
				<title>Bootstrapping options</title>
				<tgroup cols="4">
					<colspec colname="c1" colnum="1" colwidth="1*"/>
					<colspec colname="c2" colnum="2" colwidth="2*"/>
					<colspec colname="c3" colnum="3" colwidth="1*"/>
					<colspec colname="c4" colnum="4" colwidth="1.63*"/>
					<thead>
						<row>
							<entry>Name</entry>
							<entry>Method</entry>
							<entry>Default</entry>
							<entry>System Property</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><b>Enabling Encryption</b></entry>
							<entry><codeph>sslEnabled(boolean)</codeph></entry>
							<entry><codeph>false</codeph></entry>
							<entry><codeph>sslEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If encrypted communication should be
								enabled. This feature is only available against a Couchbase Server
								3.0 EE cluster or later. Please see the "Connection Management"
								section for more details on how to set it up properly.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>SSL Keystore Location</b></entry>
							<entry><codeph>sslKeystoreFile(String)</codeph></entry>
							<entry><codeph>[empty]</codeph></entry>
							<entry><codeph>sslKeystoreFile</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The location to the JVM keystore where
								the certificates are stored. This feature is only available against
								a Couchbase Server 3.0 EE cluster or later. See the "Connection
								Management" section for more details on how to set it up
								properly.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>SSL Keystore Password</b></entry>
							<entry><codeph>sslKeystorePassword(String)</codeph></entry>
							<entry><codeph>[empty]</codeph></entry>
							<entry><codeph>sslKeystorePassword</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The password of the JVM keystore where
								the certificates are stored. This feature is only available against
								a Couchbase Server 3.0 EE cluster or later. Please see the
								"Connection Management" section for more details on how to set it up
								properly.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>N1QL Enabled</b></entry>
							<entry><codeph>queryEnabled(boolean)</codeph></entry>
							<entry><codeph>false</codeph></entry>
							<entry><codeph>queryEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If experimental support for N1Ql should
								be enabled. Note that this setting is going to be deprecated as soon
								as the server comes with N1QL embedded, because it will be
								advertised and picked up by the SDK automatically. This setting
								should only be used to explicitly enable the N1QL service against a
								standalone N1QL. In addition, every Couchbase Server node in the
								cluster is expected to run a N1QL instance when this flag is
								enabled.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>N1QL Port</b></entry>
							<entry><codeph>queryPort(int)</codeph></entry>
							<entry><codeph>8093</codeph></entry>
							<entry><codeph>queryPort</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">Defines the port for the experimental
								N1QL support when enabled. Every node in the cluster is expected to
								run a N1QL service against this port. This setting is going to be
								deprecated as soon as the server comes with N1QL embedded, because
								it will be advertised and picked up by the SDK automatically. This
								setting should only be used to explicitly enable the N1QL service
								against a stand-alone N1QL.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config Loading through HTTP</b></entry>
							<entry><codeph>bootstrapHttpEnabled(boolean)</codeph></entry>
							<entry><codeph>true</codeph></entry>
							<entry><codeph>bootstrapHttpEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If it should be possible for the client
								to bootstrap and grab configurations over the HTTP port 8091 (and
								also attach a streaming connection). If you are running Couchbase
								Server 2.2 or earlier, this setting must be set to true. Against
								newer clusters it can be disabled, but it doesn't hurt to keep it
								enabled as a last-resort fallback option. Also, if configuration
								loading through carrier publication is manually disabled, this
								option is used as a fallback. If both option are disabled, the
								client is not able to function properly. If you don't have a good
								reason to disable it (for example as instructed by Couchbase
								Support), keep it enabled.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config HTTP Non-Encrypted Port</b></entry>
							<entry><codeph>bootstrapHttpDirectPort(int)</codeph></entry>
							<entry><codeph>8091</codeph></entry>
							<entry><codeph>bootstrapHttpDirectPort</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The port which is used if encryption is
								not enabled and the client needs to bootstrap through HTTP. In
								general, there is no need to change this value (unless you run a
								custom Couchbase Server build during development or testing that
								runs on different ports).</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config HTTP Encrypted Port</b></entry>
							<entry><codeph>bootstrapHttpSslPort(int)</codeph></entry>
							<entry><codeph>18091</codeph></entry>
							<entry><codeph>bootstrapHttpSslPort</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The port which is used if encryption is
								enabled and the client needs to bootstrap through HTTP. In general,
								there is no need to change this value (unless you run a custom
								Couchbase Server build during development or testing that runs on
								different ports).</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config Loading through Carrier Publication</b></entry>
							<entry><codeph>bootstrapCarrierEnabled(boolean)</codeph></entry>
							<entry><codeph>true</codeph></entry>
							<entry><codeph>bootstrapCarrierEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If you are running Couchbase Server 2.5
								or later, this is the preferred way to bootstrap and grab
								configurations. It is not done over HTTP, but through the key-value
								connections automatically. If this setting is manually disabled, the
								client will fallback to HTTP (if enabled). If both option are
								disabled, the client is not able to function properly. If you don't
								have a good reason to disable it (for example as instructed by
								Couchbase Support), keep it enabled.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config Carrier Non-Encrypted Port</b></entry>
							<entry><codeph>bootstrapCarrierDirectPort(int)</codeph></entry>
							<entry><codeph>11210</codeph></entry>
							<entry><codeph>bootstrapCarrierDirectPort</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The port which is used if encryption is
								not enabled and the client needs to bootstrap through carrier
								publication. In general, there is no need to change this value
								(unless you run a custom Couchbase Server build during development
								or testing that runs on different ports).</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Config Carrier Encrypted Port</b></entry>
							<entry><codeph>bootstrapCarrierSslPort(int)</codeph></entry>
							<entry><codeph>11207</codeph></entry>
							<entry><codeph>bootstrapCarrierSslPort</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The port which is used if encryption is
								enabled and the client needs to bootstrap through carrier
								publication. In general, there is no need to change this value
								(unless you run a custom Couchbase Server build during development
								or testing that runs on different ports).</entry>
						</row>
						<row>
							<entry><b>DNS SRV Enabled</b></entry>
							<entry><codeph>dnsSrvEnabled(boolean)</codeph></entry>
							<entry><codeph>false</codeph></entry>
							<entry><codeph>dnsSrvEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">Enable manually if you explicitly want
								to grab a bootstrap node list through a DNS SRV record. See the
								"Connection Management" section for more information on how to use
								it properly.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
						<row>
							<entry><b>Mutation Tokens Enabled</b></entry>
							<entry><codeph>mutationTokensEnabled(boolean)</codeph></entry>
							<entry><codeph>false</codeph></entry>
							<entry><codeph>mutationTokensEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If mutation tokens should be enabled,
								adding more overhead to every mutation but providing enhanced
								durability requirements as well as advanced N1QL querying
								capabilities.</entry>
							<entry/>
							<entry/>
							<entry/>
						</row>
					</tbody>
				</tgroup>
			</table>


			<p>Timeouts apply only for blocking operations. All asynchronous operations must chain in their
				own <codeph>timeout()</codeph> operators in order to apply a timeout. All default values
				can be overridden through the overloaded methods that accept both a time and time unit.
				All timeouts are reasonable defaults and should be adjusted to the environments after
				profiling the expected latencies.</p>

			<table>
				<title>Timeout options</title>
				<tgroup cols="4">
					<colspec colname="c1" colnum="1" />
					<colspec colname="c2" colnum="2" />
					<colspec colname="c3" colnum="3" />
					<colspec colname="c4" colnum="4" />
					<thead>
						<row>
							<entry>Name</entry>
							<entry>Method</entry>
							<entry>Default</entry>
							<entry>System Property</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><b>Key-Value Timeout</b></entry>
							<entry><codeph>kvTimeout(long)</codeph></entry>
							<entry><codeph>2500ms</codeph></entry>
							<entry><codeph>kvTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The Key/Value default timeout is used on all blocking operations which are performed on a specific key if not overridden by a custom timeout. It does not affect asynchronous operations. This includes all commands like <codeph>get()</codeph>, <codeph>getFromReplica()</codeph> and all mutation commands.</entry>
						</row>
						<row>
							<entry><b>View Timeout</b></entry>
							<entry><codeph>viewTimeout(long)</codeph></entry>
							<entry><codeph>75000ms</codeph></entry>
							<entry><codeph>viewTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The View timeout is used on both regular and geospatial view operations if not overridden by a custom timeout. It does not affect asynchronous operations. Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows. Also, if there is a node failure during the request the internal cluster timeout is set to 60 seconds.</entry>
						</row>
						<row>
							<entry><b>Query Timeout</b></entry>
							<entry><codeph>queryTimeout(long)</codeph></entry>
							<entry><codeph>75000ms</codeph></entry>
							<entry><codeph>queryTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The Query timeout is used on all N1QL query operations if not overridden by a custom timeout. It does not affect asynchronous operations. Note that it is set to such a high timeout compared to key/value since it can affect hundreds or thousands of rows.</entry>
						</row>
						<row>
							<entry><b>Connect Timeout</b></entry>
							<entry><codeph>connectTimeout(long)</codeph></entry>
							<entry><codeph>5000ms</codeph></entry>
							<entry><codeph>connectTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The connect timeout is used when a <codeph>Bucket</codeph> is opened and if not overridden by a custom timeout. It does not affect asynchronous operations. If you feel the urge to change this value to something higher, there is a good chance that your network is not properly set up. Opening a bucket should in practice not take longer than a second on a resonably fast network.</entry>
						</row>
						<row>
							<entry><b>Disconnect Timeout</b></entry>
							<entry><codeph>disconnectTimeout(long)</codeph></entry>
							<entry><codeph>25000ms</codeph></entry>
							<entry><codeph>disconnectTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The disconnect timeout is used when a <codeph>Cluster</codeph> is disconnect or a <codeph>Bucket</codeph> is closed synchronously and if not overridden by a custom timeout. It does not affect asynchronous operations. A timeout is applied here always to make sure that your code does not get stuck at shutdown. 25 seconds should provide enough room to drain all outstanding operations properly, but make sure to adapt this timeout to fit your application requirements.</entry>
						</row>
						<row>
							<entry><b>Management Timeout</b></entry>
							<entry><codeph>managementTimeout(long)</codeph></entry>
							<entry><codeph>75000ms</codeph></entry>
							<entry><codeph>managementTimeout</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The management timeout is used on all synchronous <codeph>BucketManager</codeph> and <codeph>ClusterManager</codeph> operations and if not overridden by a custom timeout. It set to a quite high timeout because some operations might take a longer time to complete (for example <codeph>flush</codeph>).</entry>
						</row>
					</tbody>
				</tgroup>
			</table>

			<table>
				<title>Reliability options</title>
				<tgroup cols="4">
					<colspec colname="c1" colnum="1" />
					<colspec colname="c2" colnum="2" />
					<colspec colname="c3" colnum="3" />
					<colspec colname="c4" colnum="4" />
					<thead>
						<row>
							<entry>Name</entry>
							<entry>Method</entry>
							<entry>Default</entry>
							<entry>System Property</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><b>Reconnect Delay</b></entry>
							<entry><codeph>reconnectDelay(Delay)</codeph></entry>
							<entry><codeph>Exponential between 32ms and 4096ms</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The reconnect delay defines the time intervals between a
								socket getting closed on the SDK side and trying to reopen (reconnect) to
								it. The default is to retry relatively quickly (32ms) and then gradually
								approach 4 second intervals, so that in case a server is longer down than
								usual the clients do not flood the server with socket requests. Feel free to
								tune this interval based on your application requirements. Applying a very
								large ceiling may lead to longer down times than needed, while very short
								delays may flood the target node and spam the network unnecessarily.</entry>
						</row>
						<row>
							<entry><b>Retry Delay</b></entry>
							<entry><codeph>retryDelay(Delay)</codeph></entry>
							<entry><codeph>Exponential between 100µs and 100ms</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">When a request needs to be retried for some reason (for
								example if the retry strategy is best effort and the target node is not
								reachable), this delay configures the boundaries. An internal counter tracks
								the number of retries for a given request and it gradually increases by
								default from a very quick 100 microseconds up to a 100 millisecond delay.
								The operation will be retried until it succeeds or the maximum request
								lifetime is reached. If you find yourself wanting to tweak this value to a
								very low setting, you might want to consider a different retry strategy like
								"fail fast" to get tighter control on the retry handling yourself.</entry>
						</row>
						<row>
							<entry><b>Retry Strategy</b></entry>
							<entry><codeph>retryStrategy(RetryStrategy)</codeph></entry>
							<entry><codeph>Best Effort</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The retry strategy decides if an operation should be retried
								or canceled. While implementing a custom strategy is fairly advanced, the
								SDK ships with two out of the box: <codeph>BestEffortRetryStrategy</codeph>
								and <codeph>FailFastRetryStrategy</codeph>. The first one will retry the
								operation until it either succeeds or the maximum request lifetime is
								reached. The fail fast strategy will cancel it right away and therefore the
								client needs to be prepared to retry on its own, but gets much tighter
								control on when and how to retry. See the advanced section in the
								documentation on more specific information on retry strategies and failure
								management.</entry>
						</row>
						<row>
							<entry><b>Maximum Request Lifetime</b></entry>
							<entry><codeph>maxRequestLifetime(long)</codeph></entry>
							<entry><codeph>75000ms</codeph></entry>
							<entry><codeph>maxRequestLifetime</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The maximum request lifetime is used by the best effort retry
								strategy to decide if its time to cancel the request instead of retrying it
								again. This is needed in order to prevent requests from circling around
								forever and occupying precious slots in the request ring buffer. Make sure
								to set this higher than the largest timeout in your application, otherwise
								you risk requests being canceled prematurely. This is why the default value
								is set to 75 seconds, which is the highest default timeout on the
								environment.</entry>
						</row>
						<row>
							<entry><b>Socket Keepalive Interval</b></entry>
							<entry><codeph>keepAliveInterval(long)</codeph></entry>
							<entry><codeph>30000ms</codeph></entry>
							<entry><codeph>keepAliveInterval</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">To avoid nasty firewalls and other network equipment cutting
								of stale TCP connections, at the configured interval the client will send a
								heartbeat keepalive message to the remote node and port. This only happens
								if for the given amount of time no traffic has happened, so if a socket is
								busy sending data back and forth it will have no effect. If you set this
								value to 0, no keepalive will be sent over the sockets.</entry>
						</row>
					</tbody>
				</tgroup>
			</table>

			<table>
				<title>Performance options</title>
				<tgroup cols="4">
					<colspec colname="c1" colnum="1" />
					<colspec colname="c2" colnum="2" />
					<colspec colname="c3" colnum="3" />
					<colspec colname="c4" colnum="4" />
					<thead>
						<row>
							<entry>Name</entry>
							<entry>Method</entry>
							<entry>Default</entry>
							<entry>System Property</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><b>Observe Interval</b></entry>
							<entry><codeph>observeIntervalDelay(Delay)</codeph></entry>
							<entry><codeph>Exponential between 10µs and 100ms</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The way <codeph>PersistTo</codeph> and
									<codeph>ReplicateTo</codeph> work is that once the regular mutation
								operation succeeds, the key state on the target nodes is polled until the
								desired state is reached. Since replication and persistence latency differs
								greatly on servers (fast or slow networks and disks), this value can be
								tuned for maximum efficiency. The tradeoffs to consider here is how quickly
								the desired state is detected as well as how much the SDK will spam the
								network. The default is an exponential delay, starting with very short
								intervals but very quickly approaching the 100 milliseconds if replication
								or persistence takes longer than expected. You should monitor the average
								persistence and replication latency and adjust the delay
								accordingly.</entry>
						</row>
						<row>
							<entry><b>Key/Value Endpoints per Node</b></entry>
							<entry><codeph>kvEndpoints(int)</codeph></entry>
							<entry><codeph>1</codeph></entry>
							<entry><codeph>kvEndpoints</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The number of actual endpoints (sockets) to open per Node in the cluster against the Key/value service. By default, for every node in the cluster one socket is opened where all traffic is pushed through. That way the SDK implicitly benefits from network batching characteristics when the workload increases. If you suspect based on profiling and benchmarking that the socket is saturated you can think about slightly increasing it to have more "parallel pipelines". This might be especially helpful if you need to push large documents through it. The recommendation is keeping it at 1 unless there is other evidence.</entry>
						</row>
						<row>
							<entry><b>View Endpoints per Node</b></entry>
							<entry><codeph>viewEndpoints(int)</codeph></entry>
							<entry><codeph>1</codeph></entry>
							<entry><codeph>viewEndpoints</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The number of actual endpoints (sockets) to open per node in
								the cluster against the view service. By default only one socket is opened
								to avoid unnecessary wasting resources. If you plan to run a view heavy
								workload, especially paired with larger responses, increasing this value
								significantly (most likely between 5 and 10) can provide greater throughput.
								Keep in mind that these sockets will then be always open, even when no load
								is passed through. We recommend that you tune this value based on evidence
								obtained during benchmarking with a real workload. If no view load is
								expected, setting this value explicitly to 0 can avoid one socket to 8092
								per node.</entry>
						</row>
						<row>
							<entry><b>Query Endpoints per Node</b></entry>
							<entry><codeph>queryEndpoints(int)</codeph></entry>
							<entry><codeph>1</codeph></entry>
							<entry><codeph>queryEndpoints</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The number of actual endpoints (sockets) to open per Node in
								the cluster against the Query (N1QL) service. By default only one socket is
								opened to avoid unnecessary wasting resources. If you plan to run a query
								heavy workload, especially paired with larger responses, increasing this
								value significantly (most likely between 5 and 10) can provide greater
								throughput. Keep in mind that these sockets will then be always open, even
								when no load is passed through. We are recommending to tune this value based
								on evidence during benchmarking with a real workload. If no query load is
								expected, setting this value explicitly to 0 can avoid one socket to 8093
								per node.</entry>
						</row>
						<row>
							<entry><b>I/O Thread Pool Size</b></entry>
							<entry><codeph>ioPoolSize(int)</codeph></entry>
							<entry><codeph>Runtime#availableProcessors()</codeph></entry>
							<entry><codeph>ioPoolSize</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The number of threads in the I/O thread pool. This defaults
								to the number of available processors that the runtime returns (which, as a
								well known fact,  sometimes does not represent the actual number of
								processors). Every thread represents an internal event loop where all needed
								socket are multiplexed on. The default value should be fine most of the
								time, it may only need to be tuned if you run a very large number of nodes
								in the cluster or the runtime value is incorrect. As a rule of thumb, it
								should roughly correlate with the number of cores available to the
								JVM.</entry>
						</row>
						<row>
							<entry><b>Computation Thread Pool Size</b></entry>
							<entry><codeph>computationPoolSize(int)</codeph></entry>
							<entry><codeph>Runtime#availableProcessors()</codeph></entry>
							<entry><codeph>computationPoolSize</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The number of threads in the computation thread pool. This
								defaults to the number of available processors that the runtime returns
								(which, as a well known fact, sometimes does not represent the actual number
								of processors). Every thread represents an internal event loop where all
								needed computation tasks are run. The default value should be fine most of
								the time, it might only need to be tuned if you run more than usual
								CPU-intensive tasks and profiling the application indicates fully saturated
								threads in the pool. As a rule of thumb, it should roughly correlate with
								the number of cores available to the JVM.</entry>
						</row>
						<row>
							<entry><b>I/O Pool Group</b></entry>
							<entry><codeph>ioPool(EventLoopGroup)</codeph></entry>
							<entry><codeph>NioEventLoopGroup</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">For those who want the last drop of performance, on Linux Netty provides a way to use edge triggered epoll instead of going through JVM NIO. This provides better throughput, lower latency and less garbage. Note that this mode has not been tested by Couchbase and therefore is not supported officially. If you like to take a walk on the wild side, you can find out more here: <xref href="https://github.com/netty/netty/wiki/Native-transports" format="html" scope="external">Netty Native-transports</xref>.</entry>
						</row>
						<row>
							<entry><b>TCP Nodelay</b></entry>
							<entry><codeph>tcpNodelayEnabled(boolean)</codeph></entry>
							<entry><codeph>true</codeph></entry>
							<entry><codeph>tcpNodelayEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">By default, TCP Nodelay is turned on (which in effect turns off "nagleing"), and if possible negotiated with the server as well. If this is set to false, "nagleing" is turned on. Make sure to only turn off TCP nodelay if you know what you are doing, because it can lead to decreased performance.</entry>
						</row>
					</tbody>
				</tgroup>
			</table>


			<p>Values for the advanced options listed in the following table should not be changed unless
				there is a very good reason to do so.</p>

			<table>
				<title>Advanced options</title>
				<tgroup cols="4">
					<colspec colname="c1" colnum="1" colwidth="1*"/>
					<colspec colname="c2" colnum="2" colwidth="4.13*"/>
					<colspec colname="c3" colnum="3" colwidth="2.26*"/>
					<colspec colname="c4" colnum="4" colwidth="1.3*"/>
					<thead>
						<row>
							<entry>Name</entry>
							<entry>Method</entry>
							<entry>Default</entry>
							<entry>System Property</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry><b>Request Ring Buffer Size</b></entry>
							<entry><codeph>requestBufferSize(int)</codeph></entry>
							<entry><codeph>16384</codeph></entry>
							<entry><codeph>requestBufferSize</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The size of the request ring buffer
								where all request initially are stored and then picked up to be
								pushed onto the I/O threads. Tuning this to a lower value will more
								quickly lead to <codeph>BackpressureExceptions</codeph> during
								overload or failure scenarios. Setting it to a higher value means
								backpressure will take longer to occur, but more requests will
								potentially be queued up and more heap space is used.</entry>
						</row>
						<row>
							<entry><b>Response Ring Buffer Size</b></entry>
							<entry><codeph>responseBufferSize(int)</codeph></entry>
							<entry><codeph>16384</codeph></entry>
							<entry><codeph>responseBufferSize</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The size of the response ring buffer
								where all responses are passed through from the I/O threads before
								the target <codeph>Observable</codeph> is completed. Since the I/O
								threads are pushing data in this ring buffer, setting it to a lower
								value is likely to have a negative effect on I/O performance. In
								general it should be kept in line with the request ring buffer
								size.</entry>
						</row>
						<row>
							<entry><b>Computation Scheduler</b></entry>
							<entry><codeph>scheduler(Scheduler)</codeph></entry>
							<entry><codeph>CoreScheduler</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The scheduler used for all
								CPU-intensive, non-blocking computations in the core, client and in
								user space. This is a slightly modified version of the
									<codeph>ComputationScheduler</codeph> that ships with RxJava,
								mainly for the reason to manually name threads as needed. Changing
								the scheduler should be used with extra care, especially since lots
								of internal components also depend on it.</entry>
						</row>
						<row>
							<entry><b>User Agent String</b></entry>
							<entry><codeph>userAgent(String)</codeph></entry>
							<entry><codeph>Based on OS, Runtime </codeph>
								<p><codeph>and SDK Version</codeph></p></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The user agent string that is used to
								identify the SDK against the Couchbase Server cluster on different
								occasions, for example when doing a view or query request. There is
								no need to tune that because it is dynamically generated based on
								properties set during build time (based on the package name and
								version, OS and runtime).</entry>
						</row>
						<row>
							<entry><b>Package Name and Version Identifier</b></entry>
							<entry><codeph>packageNameAndVersion(String)</codeph></entry>
							<entry><codeph>Based on SDK Version</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The package name and identifier is used
								as part of the user agent string and in the environment info output
								to see which version of the SDK the application is running. There is
								no need to change it because it is dynamically generated based on
								properties set during build time.</entry>
						</row>
						<row>
							<entry><b>Event Bus</b></entry>
							<entry><codeph>eventBus(EventBus)</codeph></entry>
							<entry><codeph>DefaultEventBus</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The event bus implementation used to
								transport system, performance and debug events from producers to
								subscribers. The default implementation is based on an internal
								RxJava Subject which does not cache the values and only pushes
								subsequent events to the subscribers. If you provide a custom
								implementation, double check that it fits with the contract of the
								event bus as documented.</entry>
						</row>
						<row>
							<entry><b>DCP Enabled</b></entry>
							<entry><codeph>dcpEnabled(boolean)</codeph></entry>
							<entry><codeph>false</codeph></entry>
							<entry><codeph>dcpEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">DCP is not ready for prime time in
								clients, but this configuration switch is available because all
								parameters from the <codeph>core-io</codeph> module are inherited.
								If you have active need for DCP, get in touch with the Couchbase
								team.</entry>
						</row>
						<row>
							<entry><b>Buffer Pooling Enabled</b></entry>
							<entry><codeph>bufferPoolingEnabled(boolean)</codeph></entry>
							<entry><codeph>true</codeph></entry>
							<entry><codeph>bufferPoolingEnabled</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">If the SDK is suspect to buffer leaks
								(it pools buffers in its IO layer for performance) you can set this
								field to false. This will make sure buffers are not pooled, but
								remember the tradeoff here is higher GC pressure on the system. Only
								turn off to prevent a memory leak from happening (in production). If
								you suspect a memory leak, please open a bug ticket.</entry>
						</row>
						<row>
							<entry><b>Runtime Metrics Collector</b></entry>
							<entry><codeph>runtimeMetricsCollectorConfig
									(MetricsCollectorConfig)</codeph></entry>
							<entry><codeph>DefaultMetricsCollectorConfig</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The configuration of the runtime metrics
								collector can be modified (or completely disabled). By default, it
								will emit an event every hour.</entry>
						</row>
						<row>
							<entry><b>Network Latency Metrics Collector</b></entry>
							<entry><codeph>networkLatencyMetricsCollectorConfig
									(LatencyMetricsCollectorConfig)</codeph></entry>
							<entry><codeph>DefaultLatencyMetricsCollectorConfig</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The configuration of the network latency
								metrics collector can be modified (or completely disabled). By
								deault, it will emit an event every hour, but collect the stats all
								the time.</entry>
						</row>
						<row>
							<entry><b>Default Metrics Consumer</b></entry>
							<entry><codeph>defaultMetricsLoggingConsumer</codeph></entry>
							<entry><codeph>(boolean, CouchbaseLogLevel,OutputFormat)</codeph></entry>
							<entry><codeph>enabled, INFO, JSON</codeph></entry>
							<entry><codeph>-</codeph></entry>
						</row>
						<row>
							<entry namest="c1" nameend="c4">The default metric consumer which will
								log all metric events. You can configure if it should be enabled, as
								well as the log level and the target output format.</entry>
						</row>
					</tbody>
				</tgroup>
			</table>

		</section>
	</conbody>
</concept>
